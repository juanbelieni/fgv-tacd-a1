{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 – Model Comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - For the classification problem (you developed the estimator in Part 2) you will use all the\n",
    "numerical features and predict the “cut”. The steps to implement are:\n",
    "\n",
    "- Select 3 classifiers from the scikit-learn library (you can pick any classifier of your choice,\n",
    "  including those not seen in class yet).\n",
    "- For each model (your model as well as the scikit-learn ones), use the training and\n",
    "  validation sets to choose the best hyperparameters.\n",
    "- Combine the training and validation sets into a single set and use it to train the models\n",
    "  with the chosen hyperparameters.\n",
    "- Compare the performance of the different estimators using the accuracy score.\n",
    "- Make a plot that shows this comparison (here you can use any type of plot you like, as\n",
    "  long as the comparison is clear).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing everything done in part-2.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "diamonds_dataset = pd.read_csv(\"../data/diamonds.csv\")\n",
    "\n",
    "n = len(diamonds_dataset)\n",
    "splits = [int(0.8 * n), int(0.9 * n)]\n",
    "training, validation, testing = np.split(diamonds_dataset.sample(frac=1), splits)\n",
    "\n",
    "\n",
    "class KNNClassifier(BaseEstimator):\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, distances=\"euclidean\"):\n",
    "        n_samples = X.shape[0]\n",
    "        predictions = np.empty(n_samples, dtype=object)\n",
    "\n",
    "        if distances == \"euclidean\":\n",
    "            for i in range(n_samples):\n",
    "                point_distances = np.sum(np.square(self.X - X[i, :]), axis=1)\n",
    "                idx = np.argpartition(point_distances, self.k)[: self.k]\n",
    "\n",
    "                values, counts = np.unique(self.y[idx], return_counts=True)\n",
    "\n",
    "                predictions[i] = values[np.argmax(counts)]\n",
    "        else:\n",
    "            for i in range(n_samples):\n",
    "                point_distances = self.distances[i, :]\n",
    "                idx = np.argpartition(point_distances, self.k)[: self.k]\n",
    "\n",
    "                values, counts = np.unique(self.y[idx], return_counts=True)\n",
    "\n",
    "                predictions[i] = values[np.argmax(counts)]\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing 3 classifiers from sciki-learn\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNNClassifier(k=2): 0.59%\n",
      "KNNClassifier(k=10): 0.55%\n",
      "KNNClassifier(k=50): 0.48%\n",
      "KNNClassifier(k=100): 0.45%\n",
      "KNeighborsClassifier(n_neighbors=2): 0.59%\n",
      "KNeighborsClassifier(n_neighbors=10): 0.55%\n",
      "KNeighborsClassifier(n_neighbors=50): 0.48%\n",
      "KNeighborsClassifier(n_neighbors=100): 0.45%\n",
      "DecisionTreeClassifier(max_depth=2): 0.67%\n",
      "DecisionTreeClassifier(max_depth=10): 0.74%\n",
      "DecisionTreeClassifier(max_depth=50): 0.70%\n",
      "DecisionTreeClassifier(max_depth=100): 0.71%\n",
      "RandomForestClassifier(n_estimators=2): 0.71%\n",
      "RandomForestClassifier(n_estimators=10): 0.74%\n",
      "RandomForestClassifier(n_estimators=50): 0.79%\n",
      "RandomForestClassifier(n_estimators=100): 0.78%\n"
     ]
    }
   ],
   "source": [
    "# Testing the hyperparameters\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "features = [\"carat\", \"depth\", \"table\", \"price\", \"x\", \"y\", \"z\"]\n",
    "target = \"cut\"\n",
    "\n",
    "estimators = []\n",
    "\n",
    "X_train, y_train = training[features].to_numpy(), training[target].to_numpy()\n",
    "X_validation, y_validation = (\n",
    "    validation[features].to_numpy()[:500],\n",
    "    validation[target].to_numpy()[:500],\n",
    ")\n",
    "\n",
    "for k in [2, 10, 50, 100]:\n",
    "    estimator = KNNClassifier(k=k)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    predictions = estimator.predict(X_validation)\n",
    "\n",
    "    accuracy = accuracy_score(y_validation, predictions)\n",
    "    estimators.append((\"KNNClassifier\", k, accuracy))\n",
    "\n",
    "    print(f\"KNNClassifier(k={k}): {accuracy:.2f}%\")\n",
    "\n",
    "for k in [2, 10, 50, 100]:\n",
    "    estimator = KNeighborsClassifier(n_neighbors=k)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    predictions = estimator.predict(X_validation)\n",
    "\n",
    "    accuracy = accuracy_score(y_validation, predictions)\n",
    "    estimators.append((\"KNeighborsClassifier\", k, accuracy))\n",
    "\n",
    "    print(f\"KNeighborsClassifier(n_neighbors={k}): {accuracy:.2f}%\")\n",
    "\n",
    "for k in [2, 10, 50, 100]:\n",
    "    estimator = DecisionTreeClassifier(max_depth=k)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    predictions = estimator.predict(X_validation)\n",
    "\n",
    "    accuracy = accuracy_score(y_validation, predictions)\n",
    "    estimators.append((\"DecisionTreeClassifier\", k, accuracy))\n",
    "\n",
    "    print(f\"DecisionTreeClassifier(max_depth={k}): {accuracy:.2f}%\")\n",
    "\n",
    "for k in [2, 10, 50, 100]:\n",
    "    estimator = RandomForestClassifier(n_estimators=k)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    predictions = estimator.predict(X_validation)\n",
    "\n",
    "    accuracy = accuracy_score(y_validation, predictions)\n",
    "    estimators.append((\"RandomForestClassifier\", k, accuracy))\n",
    "\n",
    "    print(f\"RandomForestClassifier(n_estimators={k}): {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNNClassifier': (KNNClassifier(k=2), 0.594),\n",
       " 'KNeighborsClassifier': (KNeighborsClassifier(n_neighbors=2), 0.594),\n",
       " 'DecisionTreeClassifier': (DecisionTreeClassifier(max_depth=10), 0.744),\n",
       " 'RandomForestClassifier': (RandomForestClassifier(n_estimators=50), 0.786)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the best estimators\n",
    "\n",
    "best_estimators = {}\n",
    "\n",
    "for name, k, accuracy in estimators:\n",
    "    estimator = None\n",
    "\n",
    "    match name:\n",
    "        case \"KNNClassifier\":\n",
    "            estimator = KNNClassifier(k=k)\n",
    "        case \"KNeighborsClassifier\":\n",
    "            estimator = KNeighborsClassifier(n_neighbors=k)\n",
    "        case \"DecisionTreeClassifier\":\n",
    "            estimator = DecisionTreeClassifier(max_depth=k)\n",
    "        case \"RandomForestClassifier\":\n",
    "            estimator = RandomForestClassifier(n_estimators=k)\n",
    "\n",
    "    if name not in best_estimators:\n",
    "        best_estimators[name] = (estimator, accuracy)\n",
    "\n",
    "    if accuracy > best_estimators[name][1]:\n",
    "        best_estimators[name] = (estimator, accuracy)\n",
    "\n",
    "best_estimators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNNClassifier</td>\n",
       "      <td>0.557286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.557286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.742677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.772525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                estimator  accuracy\n",
       "0           KNNClassifier  0.557286\n",
       "1    KNeighborsClassifier  0.557286\n",
       "2  DecisionTreeClassifier  0.742677\n",
       "3  RandomForestClassifier  0.772525"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the final accuracies\n",
    "\n",
    "accuracies = pd.DataFrame(columns=[\"estimator\", \"accuracy\"])\n",
    "\n",
    "X = np.concatenate((X_train, X_validation))\n",
    "y = np.concatenate((y_train, y_validation))\n",
    "\n",
    "X_test = testing[features].to_numpy()\n",
    "y_test = testing[target].to_numpy()\n",
    "\n",
    "for name, (estimator, _) in best_estimators.items():\n",
    "    estimator.fit(X, y)\n",
    "    predictions = estimator.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "    accuracies = pd.concat(\n",
    "        [accuracies, pd.DataFrame({\"estimator\": [name], \"accuracy\": [accuracy]})],\n",
    "        axis=0,\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='estimator', ylabel='accuracy'>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the accuracies\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "sns.barplot(data=accuracies, x=\"estimator\", y=\"accuracy\", palette=\"Blues_d\", ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - For the regression problem (you developed the estimator in Part 2) you will predict the \"price\" using the remaining numerical features. The steps to implement are:\n",
    "- Select 3 regressors from the scikit-learn library (you can pick any regressor of your\n",
    "choice, including those not seen in class yet).\n",
    "- For each model (your model as well as the scikit-learn ones), use the training and\n",
    "validation sets to choose the best hyperparameters.\n",
    "- Combine the training and validation sets into a single set and use it to train the models\n",
    "with the chosen hyperparameters.\n",
    "- Compare the performance of the different estimators using the Root Mean Square Error\n",
    "score.\n",
    "- Make a plot that shows this comparison (here you can use any type of plot you like, as\n",
    "long as the comparison is clear)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing everything done in part-3.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "diamonds_dataset = pd.read_csv(\"../data/diamonds.csv\")\n",
    "\n",
    "n = len(diamonds_dataset)\n",
    "splits = [int(0.8 * n), int(0.9 * n)]\n",
    "training, validation, testing = np.split(diamonds_dataset.sample(frac=1), splits)\n",
    "\n",
    "\n",
    "class LinearRegression(BaseEstimator):\n",
    "    def __init__(\n",
    "        self, solver: str = \"sgd\", max_iter: int = 100, learning_rate: float = 0.0001\n",
    "    ):\n",
    "        self.solver = solver\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def _fit_cf(self, X: np.ndarray, y: np.ndarray):\n",
    "        n = X.shape[0]\n",
    "        regularization_term = np.sqrt(np.sum(np.square(X)) / n)\n",
    "\n",
    "        lambda_I = np.eye(X.shape[1]) * regularization_term\n",
    "        w = np.linalg.inv(X.T @ X + lambda_I) @ X.T @ y\n",
    "\n",
    "        return w\n",
    "\n",
    "    def _fit_sgd(self, X: np.ndarray, y: np.ndarray):\n",
    "        n_samples, n_features = X.shape\n",
    "        w = np.zeros(n_features)\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            for j in range(n_samples):\n",
    "                gradient = (y[j] - w @ X[j]) * X[j]\n",
    "                w += self.learning_rate * gradient\n",
    "\n",
    "        return w\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        n = X.shape[0]\n",
    "        X_ = np.c_[np.ones(n), X]\n",
    "\n",
    "        if self.solver == \"cf\":\n",
    "            self.w = self._fit_cf(X_, y)\n",
    "        elif self.solver == \"sgd\":\n",
    "            self.w = self._fit_sgd(X_, y)\n",
    "        else:\n",
    "            raise ValueError(\"Solver not implemented\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_ = np.c_[np.ones(len(X)), X]\n",
    "        return X_ @ self.w\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing 3 regressors from scikit-learn\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(max_iter=2): 2063.43\n",
      "LinearRegression(max_iter=10): 1833.52\n",
      "LinearRegression(max_iter=50): 1581.56\n",
      "LinearRegression(max_iter=100): 1562.44\n",
      "DecisionTreeRegressor(min_samples_leaf=2): 1798.42\n",
      "DecisionTreeRegressor(min_samples_leaf=10): 1507.94\n",
      "DecisionTreeRegressor(min_samples_leaf=50): 1335.14\n",
      "DecisionTreeRegressor(min_samples_leaf=100): 1377.58\n",
      "DecisionTreeRegressor(min_samples_leaf=500): 1380.07\n",
      "LinearSVR(epsilon=2): 1976.99\n",
      "LinearSVR(epsilon=100): 1974.07\n",
      "LinearSVR(epsilon=500): 1907.48\n",
      "LinearSVR(epsilon=2000): 1796.88\n",
      "LinearSVR(epsilon=5000): 3572.73\n",
      "GradientBoostingRegressor(n_estimators=2): 3377.02\n",
      "GradientBoostingRegressor(n_estimators=10): 1923.07\n",
      "GradientBoostingRegressor(n_estimators=50): 1334.65\n",
      "GradientBoostingRegressor(n_estimators=100): 1315.90\n",
      "GradientBoostingRegressor(n_estimators=500): 1322.82\n"
     ]
    }
   ],
   "source": [
    "# Testing the hyperparameters\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def rmse(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "\n",
    "features = [\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"]\n",
    "target = \"price\"\n",
    "\n",
    "estimators = []\n",
    "\n",
    "X_train, y_train = training[features].to_numpy(), training[target].to_numpy()\n",
    "X_validation, y_validation = (\n",
    "    validation[features].to_numpy()[:500],\n",
    "    validation[target].to_numpy()[:500],\n",
    ")\n",
    "\n",
    "for k in [2, 10, 50, 100]:\n",
    "    estimator = LinearRegression(solver=\"sgd\", max_iter=k)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    predictions = estimator.predict(X_validation)\n",
    "\n",
    "    error = rmse(y_validation, predictions)\n",
    "    estimators.append((\"LinearRegression\", k, error))\n",
    "\n",
    "    print(f\"LinearRegression(max_iter={k}): {error:.2f}\")\n",
    "\n",
    "for k in [2, 10, 50, 100, 500]:\n",
    "    estimator = DecisionTreeRegressor(min_samples_leaf=k)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    predictions = estimator.predict(X_validation)\n",
    "\n",
    "    error = rmse(y_validation, predictions)\n",
    "    estimators.append((\"DecisionTreeRegressor\", k, error))\n",
    "\n",
    "    print(f\"DecisionTreeRegressor(min_samples_leaf={k}): {error:.2f}\")\n",
    "\n",
    "for k in [2, 100, 500, 2000, 5000]:\n",
    "    estimator = LinearSVR(epsilon=k)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    predictions = estimator.predict(X_validation)\n",
    "\n",
    "    error = rmse(y_validation, predictions)\n",
    "    estimators.append((\"LinearSVR\", k, error))\n",
    "\n",
    "    print(f\"LinearSVR(epsilon={k}): {error:.2f}\")\n",
    "\n",
    "for k in [2, 10, 50, 100, 500]:\n",
    "    estimator = GradientBoostingRegressor(n_estimators=k)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    predictions = estimator.predict(X_validation)\n",
    "\n",
    "    error = rmse(y_validation, predictions)\n",
    "    estimators.append((\"GradientBoostingRegressor\", k, error))\n",
    "\n",
    "    print(f\"GradientBoostingRegressor(n_estimators={k}): {error:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression': (LinearRegression(), 1562.4387418037095),\n",
       " 'DecisionTreeRegressor': (DecisionTreeRegressor(min_samples_leaf=50),\n",
       "  1335.1430831919909),\n",
       " 'LinearSVR': (LinearSVR(epsilon=2000), 1796.8837323138614),\n",
       " 'GradientBoostingRegressor': (GradientBoostingRegressor(),\n",
       "  1315.8974813097889)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the best estimators\n",
    "\n",
    "best_estimators = {}\n",
    "\n",
    "for name, k, error in estimators:\n",
    "    estimator = None\n",
    "\n",
    "    match name:\n",
    "        case \"LinearRegression\":\n",
    "            estimator = LinearRegression(solver=\"sgd\", max_iter=k)\n",
    "        case \"DecisionTreeRegressor\":\n",
    "            estimator = DecisionTreeRegressor(min_samples_leaf=k)\n",
    "        case \"LinearSVR\":\n",
    "            estimator = LinearSVR(epsilon=k)\n",
    "        case \"GradientBoostingRegressor\":\n",
    "            estimator = GradientBoostingRegressor(n_estimators=k)\n",
    "\n",
    "    if name not in best_estimators:\n",
    "        best_estimators[name] = (estimator, error)\n",
    "\n",
    "    if error < best_estimators[name][1]:\n",
    "        best_estimators[name] = (estimator, error)\n",
    "\n",
    "best_estimators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>1516.279192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>1361.087842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVR</td>\n",
       "      <td>1783.632612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>1322.456299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   estimator        error\n",
       "0           LinearRegression  1516.279192\n",
       "1      DecisionTreeRegressor  1361.087842\n",
       "2                  LinearSVR  1783.632612\n",
       "3  GradientBoostingRegressor  1322.456299"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the final errors\n",
    "\n",
    "errors = pd.DataFrame(columns=[\"estimator\", \"error\"])\n",
    "\n",
    "X = np.concatenate((X_train, X_validation))\n",
    "y = np.concatenate((y_train, y_validation))\n",
    "\n",
    "X_test = testing[features].to_numpy()\n",
    "y_test = testing[target].to_numpy()\n",
    "\n",
    "for name, (estimator, _) in best_estimators.items():\n",
    "    estimator.fit(X, y)\n",
    "    predictions = estimator.predict(X_test)\n",
    "\n",
    "    error = rmse(y_test, predictions)\n",
    "\n",
    "    errors = pd.concat(\n",
    "        [errors, pd.DataFrame({\"estimator\": [name], \"error\": [error]})],\n",
    "        axis=0,\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='estimator', ylabel='error'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the accuracies\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = errors.sort_values(by=\"error\")\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "sns.barplot(data=data, x=\"estimator\", y=\"error\", palette=\"flare\", ax=ax)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "328aee3b155a068886fab24c8a017cee24eb81c3e59bc834938456388e09f401"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
